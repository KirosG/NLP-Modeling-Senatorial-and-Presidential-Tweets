{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tweets From Senators, Obama, Trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv('../capstone/ALLDATA_2.csv')\n",
    "\n",
    "df_all = pd.DataFrame(data_all)\n",
    "\n",
    "df_all.drop(columns = 'Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288799, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>user</th>\n",
       "      <th>party</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/16/17 22:59</td>\n",
       "      <td>I'm grateful to @SenJohnMcCain for his lifetim...</td>\n",
       "      <td>https://twitter.com/BarackObama/status/9200615...</td>\n",
       "      <td>17064</td>\n",
       "      <td>89916</td>\n",
       "      <td>641842</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/2/17 12:41</td>\n",
       "      <td>Michelle &amp; I are praying for the victims in La...</td>\n",
       "      <td>https://twitter.com/BarackObama/status/9148326...</td>\n",
       "      <td>21588</td>\n",
       "      <td>405895</td>\n",
       "      <td>1715753</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       created_at                                               text  \\\n",
       "0  10/16/17 22:59  I'm grateful to @SenJohnMcCain for his lifetim...   \n",
       "1   10/2/17 12:41  Michelle & I are praying for the victims in La...   \n",
       "\n",
       "                                                 url  replies  retweets  \\\n",
       "0  https://twitter.com/BarackObama/status/9200615...    17064     89916   \n",
       "1  https://twitter.com/BarackObama/status/9148326...    21588    405895   \n",
       "\n",
       "   favorites         user  party state  \n",
       "0     641842  BarackObama      1    US  \n",
       "1    1715753  BarackObama      1    US  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_all.shape)\n",
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Was this tweet written by a Republican or Democrat? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((231039,), (57760,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up X and y\n",
    "X = df_all['text']\n",
    "y = df_all['party']\n",
    "\n",
    "# Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                   random_state = 18, \n",
    "                                                   test_size = 0.20, \n",
    "                                                   stratify = y\n",
    "                                                   )\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count Vectorizer & Multinomial Naiive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cv__stop_words': [None, 'english'], 'cv__min_df': [1, 2, 3], 'cv__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating models \n",
    "\n",
    "mnb = MultinomialNB()\n",
    "cv = CountVectorizer()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cv', cv), \n",
    "    ('mnb', mnb)\n",
    "])\n",
    "\n",
    "params = { \n",
    "    \"cv__stop_words\": [None, \"english\"], \n",
    "    \"cv__min_df\": [1,2,3], \n",
    "    \"cv__ngram_range\": [(1,1), (1,2),(2,2)]\n",
    "}\n",
    "\n",
    "gs_mnb = GridSearchCV(pipe, \n",
    "                     param_grid = params)\n",
    "\n",
    "gs_mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__min_df': 1, 'cv__ngram_range': (1, 2), 'cv__stop_words': 'english'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold Cross Validation Score on train data for Multinomial NB: 0.8404019606597103\n",
      "Score on test data for Multinomial NB: 0.8479774957211368\n"
     ]
    }
   ],
   "source": [
    "print(\"3-fold Cross Validation Score on train data for Multinomial NB:\", gs_mnb.best_score_)\n",
    "print(\"Score on test data for Multinomial NB:\", gs_mnb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Count Vectorizer & Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cv2', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cv2__stop_words': [None, 'english'], 'cv2__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2 = CountVectorizer()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "pipe_rf = Pipeline([ \n",
    "    (\"cv2\", cv2), \n",
    "    (\"rf\", rf)\n",
    "])\n",
    "\n",
    "params_rf = { \n",
    "    \"cv2__stop_words\": [None, \"english\"], \n",
    "    \"cv2__ngram_range\": [(1,1), (1,2), (2,2)] \n",
    "    #\"rf__criterion\": [\"gini\", \"entropy\"] \n",
    "    #\"rf__n_estimators\": [20, 27, 35]\n",
    "}\n",
    "\n",
    "gs_rf = GridSearchCV(pipe_rf,\n",
    "                     param_grid = params_rf)\n",
    "gs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv2__ngram_range': (1, 1), 'cv2__stop_words': 'english'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7840859504412332"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7936994797580113"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cv3', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'cv3__stop_words': ['english'], 'cv3__ngram_range': [(1, 2), (2, 2)], 'logreg__penalty': ['l1', 'l2'], 'logreg__C': [0.5, 0.7, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv3 = CountVectorizer()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "pipe_logreg = Pipeline([\n",
    "    ('cv3', cv3), \n",
    "    ('logreg', logreg)     \n",
    "])\n",
    "\n",
    "params_logreg = {\n",
    "    \"cv3__stop_words\": [\"english\"], \n",
    "    \"cv3__ngram_range\": [(1,2), (2,2)], \n",
    "    'logreg__penalty': ['l1', 'l2'], \n",
    "    \"logreg__C\": [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "logreg_gs = GridSearchCV(pipe_logreg, \n",
    "                        param_grid = params_logreg)\n",
    "\n",
    "logreg_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv3__ngram_range': (1, 2),\n",
       " 'cv3__stop_words': 'english',\n",
       " 'logreg__C': 1.0,\n",
       " 'logreg__penalty': 'l2'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8612095793350906"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873303324099723"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction = logreg_gs.predict(X_test)\n",
    "test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives: 3183\n",
      "False Negatives: 4135\n",
      "True Negatives: 26719\n",
      "True Positives: 23723\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, test_prediction).ravel()\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.89      0.88     29902\n",
      "          1       0.88      0.85      0.87     27858\n",
      "\n",
      "avg / total       0.87      0.87      0.87     57760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
